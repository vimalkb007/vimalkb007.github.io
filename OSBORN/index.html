<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
    content="Building a Winning Team: Selecting Source Model Ensembles using a Submodular Transferability Estimation Approach">
  <meta name="keywords" content="Ensemble, Transferability, Submodular">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Building a Winning Team: Selecting Source Model Ensembles using a Submodular Transferability Estimation
    Approach</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>

</head>

<body>

  <!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">ICCV 2023</h1><br>
            <h1 class="title is-1 publication-title">Building a Winning Team: Selecting Source Model Ensembles using a
              Submodular Transferability Estimation Approach</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="">Vimal K B*</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="">Saketh Bachu*</a><sup>1</sup><sup>,</sup><sup>3</sup>,</span>
              <span class="author-block">
                <a href="">Tanmay Garg</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="">Vineeth N Balasubramanian</a><sup>1</sup>,
              </span><br>
              <span class="author-block">
                <a href="">Niveditha Lakshmi Narasimhan</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="">Raghavan Konuru</a><sup>2</sup>
              </span>
              <!-- <span class="author-block">
              <a href="">Ricardo Martin-Brualla</a><sup>2</sup>
            </span> -->
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Indian Institute of Technology, Hyderabad, India</span>,
              <span class="author-block"><sup>2</sup>KLA</span>,
              <span class="author-block"><sup>3</sup>University of California, Riverside</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Video Link. -->
                <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <!-- <span class="link-block">
                  <a href="https://github.com/google/nerfies/releases/tag/0.1"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Data</span>
                  </a>
              </div> -->

              </div>
            </div>
          </div>
        </div>
      </div>
  </section>

  <!-- <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video id="teaser" autoplay muted loop playsinline height="100%">
          <source src="./static/videos/teaser.mp4" type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">
          <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
          free-viewpoint
          portraits.
        </h2>
      </div>
    </div>
  </section> -->


  <!-- <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-steve">
            <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/steve.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp">
            <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/chair-tp.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-shiba">
            <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/shiba.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-fullbody">
            <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/fullbody.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-blueshirt">
            <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/blueshirt.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-mask">
            <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/mask.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-coffee">
            <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/coffee.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-toby">
            <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/toby2.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section> -->


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>

            </p>
            Estimating the transferability of publicly available pre-trained models to a target task has assumed an
            important place for transfer learning tasks in recent years. Existing efforts propose metrics that allow a
            user to choose one model from a pool of pre-trained models without having to fine-tune each model
            individually and identify one explicitly. With the growth in the number of available pre-trained models and
            the popularity of model ensembles, it also becomes essential to study the transferability of multiple-source
            models for a given target task. The few existing efforts study transferability in such multi-source ensemble
            settings using just the outputs of the classification layer and neglect possible domain or task mismatch.
            Moreover, they overlook the most important factor while selecting the source models, viz., the cohesiveness
            factor between them, which can impact the performance and confidence in the prediction of the ensemble. To
            address these gaps, we propose a novel Optimal tranSport-based suBmOdular tRaNsferability metric (OSBORN) to
            estimate the transferability of an ensemble of models to a downstream task. OSBORN collectively accounts for
            image domain difference, task difference, and cohesiveness of models in the ensemble to provide reliable
            estimates of transferability. We gauge the performance of OSBORN on both image classification and semantic
            segmentation tasks. Our setup includes 28 source datasets, 11 target datasets, 5 model architectures, and 2
            pre-training methods. We benchmark our method against current state-of-the-art metrics MS-LEEP and E-LEEP,
            and outperform them consistently using the proposed approach.
          </div>
        </div>
      </div>
      <!--/ Abstract. -->

      <!-- Paper video. -->
      <!-- <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Video</h2>
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0" frameborder="0"
              allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div> -->
      <!--/ Paper video. -->
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Task Objective</h2>
          <div class="content has-text-centered">
            <p>
              <img src="static\images\OSBORN-FINAL-1.png" alt="Image Description">
            </p><br>
            Figure 1: Illustration of the objective and problem setting of our proposed metric.
          </div>
          <div class="content has-text-justified">
            <p>
              Given a source pool containing M datasets accompanied by a pre-trained model each and a target dataset,
              OSBORN selects a subset of models i.e., an Ensemble such that the Domain Difference, Task Difference are
              low
              and the Model Cohesion is high by employing a submodular approach. Please refer to Section 1 of the paper
              for more details.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Method</h2>
          <div class="content has-text-centered">
            <p>
              <img src="static\images\OSBORN-Page-12.png" alt="Image Description" width="600">
            </p><br>
            Figure 2: Overview of our method for estimating the transferability for ensembles.
          </div>
          <div class="content has-text-justified">
            <p>
              We define OSBORN for a subset of models \(M_e\) of our source pool \(M\) as follows. Our metric
              collectively
              accounts for domain difference, task difference and model cohesion. A model ensemble that obtains a low
              OSBORN score will have better transferability to a target dataset. Our experiments show that a simple
              combination of these three quantities (with no weighting co-efficients) outperforms existing methods in
              all our experiments. In our ablation studies and analysis, we study the contribution of each OSBORN
              component as well as the effect of weighting each component differently.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Results</h2>
          <div class="content has-text-centered">
            <h3 class="subtitle">Image Classification using fully-supervised learning</h3>
            <p>
              <img src="static\images\Table3.png" alt="Image Description">
            </p>
            <p>
              <!-- Placeholder for Table 3 -->
              Table 1: Comparison of different ensemble transferability estimation metrics for fully-supervised models
              (classification tasks). The best results are indicated in bold. Note: MS: MS-LEEP, E: E-LEEP, Ours:
              OSBORN.
            </p>

            <h3 class="subtitle">Image Classification using self-supervised learning</h3>
            <p>
              <img src="static\images\Table4.png" alt="Image Description">
            </p>
            <p>
              <!-- Placeholder for Table 4 -->
              Table 2: Comparison of different ensemble transferability estimation metrics for self-supervised
              pre-trained models (classification tasks). The best results are indicated in bold. Note: MS: MS-LEEP, E:
              E-LEEP and Ours: OSBORN.
            </p>
          </div>
        </div>
      </div>
    </div>
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="content has-text-centered">
            <br>
            <h3 class="subtitle">t-SNE Plots for Visualization</h3>
            <p>
              <img src="static\images\tSNE_Plots_FSL (1).png" alt="Image Description">
            </p>
            <p>
              <!-- Placeholder for Table 3 -->
              t-SNE plots of features learned by corresponding method's ensembles on StanfordCars dataset.
              <i>Optimal</i> chooses best ensemble with exhaustive search
            </p>

          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- <section class="section">
    <div class="container is-max-desktop">

      <div class="columns is-centered"> -->


        <!-- Visual Effects. -->
        <!-- <div class="column">
          <div class="content">
            <h2 class="title is-3">Visual Effects</h2>
            <p>
              Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
              would be impossible without nerfies since it would require going through a wall.
            </p>
            <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/dollyzoom-stacked.mp4" type="video/mp4">
            </video>
          </div>
        </div> -->
        <!--/ Visual Effects. -->

        <!-- Matting. -->
        <!-- <div class="column">
          <h2 class="title is-3">Matting</h2>
          <div class="columns is-centered">
            <div class="column content">
              <p>
                As a byproduct of our method, we can also solve the matting problem by ignoring
                samples that fall outside of a bounding box during rendering.
              </p>
              <video id="matting-video" controls playsinline height="100%">
                <source src="./static/videos/matting.mp4" type="video/mp4">
              </video>
            </div>

          </div>
        </div>
      </div> -->
        <!--/ Matting. -->

        <!-- Animation. -->
        <!-- <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Animation</h2>

          
          <h3 class="title is-4">Interpolating states</h3>
          <div class="content has-text-justified">
            <p>
              We can also animate the scene by interpolating the deformation latent codes of two input
              frames. Use the slider here to linearly interpolate between the left frame and the right
              frame.
            </p>
          </div>
          <div class="columns is-vcentered interpolation-panel">
            <div class="column is-3 has-text-centered">
              <img src="./static/images/interpolate_start.jpg" class="interpolation-image"
                alt="Interpolate start reference image." />
              <p>Start Frame</p>
            </div>
            <div class="column interpolation-video-column">
              <div id="interpolation-image-wrapper">
                Loading...
              </div>
              <input class="slider is-fullwidth is-large is-info" id="interpolation-slider" step="1" min="0" max="100"
                value="0" type="range">
            </div>
            <div class="column is-3 has-text-centered">
              <img src="./static/images/interpolate_end.jpg" class="interpolation-image"
                alt="Interpolation end reference image." />
              <p class="is-bold">End Frame</p>
            </div>
          </div>
          <br />
          
          <h3 class="title is-4">Re-rendering the input video</h3>
          <div class="content has-text-justified">
            <p>
              Using <span class="dnerf">Nerfies</span>, you can re-render a video from a novel
              viewpoint such as a stabilized camera by playing back the training deformations.
            </p>
          </div>
          <div class="content has-text-centered">
            <video id="replay-video" controls muted preload playsinline width="75%">
              <source src="./static/videos/replay.mp4" type="video/mp4">
            </video>
          </div>
         

        </div>
      </div> -->
        <!--/ Animation. -->


        <!-- Concurrent Work. -->
        <!-- <div class="columns is-centered">
          <div class="column is-full-width">
            <h2 class="title is-3">Related Links</h2> -->

            <!-- <div class="content has-text-justified">
            <p>
              There's a lot of excellent work that was introduced around the same time as ours.
            </p>
            <p>
              <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an
              idea similar to our windowed position encoding for coarse-to-fine optimization.
            </p>
            <p>
              <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a
                href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
              both use deformation fields to model non-rigid scenes.
            </p>
            <p>
              Some works model videos with a NeRF by directly modulating the density, such as <a
                href="https://video-nerf.github.io/">Video-NeRF</a>, <a
                href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a
                href="https://neural-3d-video.github.io/">DyNeRF</a>
            </p>
            <p>
              There are probably many more by the time you are reading this. Check out <a
                href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a
                href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
            </p>
          </div> -->
          <!-- </div>
        </div> -->
        <!--/ Concurrent Work. -->

      <!-- </div>
  </section> -->


  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{osborn,
  author    = {Vimal K B, Saketh Bachu, Tanmay Garg, Vineeth N Balasubramanian, Niveditha Lakshmi Narasimhan, Raghavan Konuru},
  title     = {Building a Winning Team: Selecting Source Model Ensembles using a Submodular Transferability Estimation
               Approach},
  journal   = {ICCV},
  year      = {2023},
}</code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              The source code for the website is borrowed from this <a href="https://github.com/nerfies/nerfies.github.io">repository</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>